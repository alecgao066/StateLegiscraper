import os
import requests
import re
import time
import string
import json

from bs4 import BeautifulSoup
from collections import defaultdict
import datetime
from datetime import date
from selenium import webdriver
import pdfplumber
import urllib.request
from urllib.parse import urljoin


def nv_scrape(webscrape_links, dir_chrome_webdriver, dir_save):
    
    """
    Webscrape function for Nevada State Legislature Website. 
    
    Parameters
    ----------
    webscrape_links : LIST
        List of direct link(s) to NV committee webpage.
        see nv_weblinks.py for lists organized by chamber and committee
    dir_chrome_webdriver : STRING
        Local directory that has Chrome Webdriver.
    dir_save : STRING
        Local directory to save pdfs (need to figure out file management).

    Returns
    -------
    All PDF files found on the webscrape_links, saved on local dir_save.
    
    """
    
    for link_index in range(len(webscrape_links)):
        driver=webdriver.Chrome(dir_chrome_webdriver)
        time.sleep(5)
        driver.get(webscrape_links[link_index]) 
        time.sleep(5)
        
        arrow01 = driver.find_element_by_id('divCommitteePageMeetings')
        arrow01.click()
        time.sleep(5)
    
        arrow02 = driver.find_element_by_id('divMeetings')
        arrow02.click()

        url = driver.page_source
        REGEX_PATTERN = r'https.*Minutes.*\.pdf'
        lines = url.split()
        meeting_regex = re.compile(REGEX_PATTERN)
        all_files = []
        
        for l in lines:
            hit = meeting_regex.findall(l)
            if hit:
                all_files.extend(hit)
                
        for filename in all_files:
            print(filename)
    
        folder_location = dir_save

        for link in all_files:
            filename = os.path.join(folder_location,"_".join(link.split('/')[4:]))
            urllib.request.urlretrieve(link, filename)
        time.sleep(30)
        
        driver.close()
        
def nv_pdftotext(dir_load, nv_json_name):
    """
    Convert all PDFs to a dictionary and then saved locally as a JSON file.
    
    Parameters
    ----------
    dir_load : STRING
        Local location of the directory holding PDFs.
    nv_json_name : STRING
        JSON file name, include full local path.

    Returns
    -------
    A single JSON file, can be loaded as dictionary to work with.

    """
    directory = dir_load
    n=0
    committee = {} 
    
    file_list = os.listdir(directory)
    file_list.sort()
    del file_list[0]
    
    for file in file_list:
        filename = directory + file
        all_text = '' 
        with pdfplumber.open(filename) as pdf:
            for pdf_page in pdf.pages:
                single_page_text = pdf_page.extract_text()
                all_text = all_text + '\n' + single_page_text
                committee[n]=all_text
        n=n+1   
                                
    with open(nv_json_name, 'w') as f: 
        json.dump(committee, f, ensure_ascii=False)    

def nv_extract_date(nv_json_path):
    """
    
    Parameters
    ----------
    Local path of nv_json generated by nv_pdftotext.
        Local path of cleaned nv_json file. 
    Returns
    -------
    A new json file with month as the keys. We can call new_json_file[month] if we want the transcripts of meetings for this month.
    Eg: call new_json_file[4], we would get the transcripts for April.

    """
    data = open(nv_json_path)
    json_file = json.load(data)

    new_json_file = defaultdict(list)

    for key in json_file.keys():
        temp = json_file[key]
        match = re.search(r'(January|February|March|April|May|June|July|August|September|October|November|December)[ ]([1-9]|[12][0-9]|3[01])[,][ ]\d{4}', temp)
        date = datetime.datetime.strptime(match.group(), '%B %d, %Y').date()
        month = date.month
        new_json_file[month].append(temp)
        
     return new_json_file

def nv_preprocess(nv_json_path, trim=None):    
    """
    Loads JSON into environment as dictionary
    Preprocesses the raw PDF export from previously generated json    
    Optional: Trims transcript to exclude list of those present and signature page/list of exhibits
    
    Parameters
    ----------
    nv_json_path : STRING
        Local path of nv_json generated by nv_pdftotext.
    trim: TRUE/Default(NONE)
        Provides option to trim transcript to spoken section and transcriber notes
        
    Returns
    -------
    Cleaned dictionary that excludes PDF formatting and (optional) front and back end 

    """
    
    file_path = open(nv_json_path,)
    data = json.load(file_path)
    
    if trim:
        for key in data:
            ##Removes list of attendees on front end
            start_location = re.search(r"(CHAIR.*[A-z]\:|Chair.*[A-z]\:)", data[key]).start() #Chair speaks first
            data[key] = data[key][start_location:] #Starts transcript from when Chair first speaks
            ##Removes signature page after submission (RESPECTFULLY SUBMITTED)
            end_location = re.search(r"(Respectfully\sSUBMITTED\:|RESPECTFULLY\sSUBMITTED\:)", data[key]).start() #Signature page starts with
            data[key] = data[key][:end_location] #End transcript just before respectfully submitted            
            ##PDF formatting
            data[key] = re.sub(r"Page\s[0-9]{1,}", "", data[key]) #Removes page number
            data[key] = re.sub(r"\n", "", data[key])
            data[key] = data[key].strip()
            data[key]=" ".join(data[key].split())

        return(data)
            
    else:
        for key in data:
            ##PDF formatting cleanup
            data[key] = re.sub(r"Page\s[0-9]{1,}", "", data[key]) #Removes page number
            data[key] = re.sub(r"\n", "", data[key])
            data[key] = data[key].strip()
            data[key]=" ".join(data[key].split())
 
        return(data)
            
"""
Sample of procedural language commonly used in hearings.

"motion passed"
"withdrew the motion"
"here to present"
"seconded motion passed"
"seconded the motion"
"second the motion"
"further testimony"
"speak in"
"for your testimony"
"floor statement"
"close the hearing"
"open the hearing"
"further discussion"
"moved to amend"
"do pass"
"senate bill"
"assembly bill"
"signature page"
"public comment"
"work session"
"adjourned"
"closing remarks"
"is there anyone"
"is that correct"
"entertain a motion"
"take testimony"
"i will close"
"i am presenting"
"to testify"
"are there any other"
"are there further"
"are there more"
"are there other"
"are there any further questions"
"are there any final questions"
"are there any final comments"
"are there any further comments"
"are there any more questions"
"are there any additional questions"
"are there any other questions"
"are there questions"
"are there any questions"
"are you in opposition"
"are you in support"
"have any questions"
"have questions"
"at this time i"
"do we have any"
"moved to"
"thank you"
"the motion carried unanimously"
"closing comments"
"hearing is closed"
"we will go to"
"we will proceed with"
"we will close out"
"we will open"
"all those in favor"
"the hearing on ab is closed"
"the hearing on sb is closed"
"the hearing on ab is open"
"the hearing on sb is open"
"discussion on the motion"
"proposed amendments"
"senate committee on natural resources"
"assembly committee on natural resources"
"else for support"
"i will now move to opposition"
"i will now move to support"
"meeting is adjourned"




"""
