import os
import requests
import re
import time
import string
import json

import urllib.request
from urllib.parse import urljoin
from bs4 import BeautifulSoup
from selenium import webdriver
import pdfplumber
import datetime
from datetime import date
from collections import defaultdict


def nv_scrape(webscrape_links, dir_chrome_webdriver, dir_save):
    
    """
    Webscrape function for Nevada State Legislature Website. 
    
    Parameters
    ----------
    webscrape_links : LIST
        List of direct link(s) to NV committee webpage.
        see nv_weblinks.py for lists organized by chamber and committee
    dir_chrome_webdriver : STRING
        Local directory that has Chrome Webdriver.
    dir_save : STRING
        Local directory to save pdfs (need to figure out file management).

    Returns
    -------
    All PDF files found on the webscrape_links, saved on local dir_save.
    
    """
    
    for link_index in range(len(webscrape_links)):
        driver=webdriver.Chrome(dir_chrome_webdriver)
        time.sleep(5)
        driver.get(webscrape_links[link_index]) 
        time.sleep(5)
        
        arrow01 = driver.find_element_by_id('divCommitteePageMeetings')
        arrow01.click()
        time.sleep(5)
    
        arrow02 = driver.find_element_by_id('divMeetings')
        arrow02.click()

        url = driver.page_source
        REGEX_PATTERN = r'https.*Minutes.*\.pdf'
        lines = url.split()
        meeting_regex = re.compile(REGEX_PATTERN)
        all_files = []
        
        for l in lines:
            hit = meeting_regex.findall(l)
            if hit:
                all_files.extend(hit)
                
        for filename in all_files:
            print(filename)
    
        folder_location = dir_save

        for link in all_files:
            filename = os.path.join(folder_location,"_".join(link.split('/')[4:]))
            urllib.request.urlretrieve(link, filename)
        time.sleep(30)
        
        driver.close()
        
def nv_pdftotext(dir_load, nv_json_name):
    """
    Convert all PDFs to a dictionary and then saved locally as a JSON file.
    
    Parameters
    ----------
    dir_load : STRING
        Local location of the directory holding PDFs.
    nv_json_name : STRING
        JSON file name, include full local path.

    Returns
    -------
    A single JSON file, can be loaded as dictionary to work with.

    """
    directory = dir_load
    n=0
    committee = {} 
    
    file_list = os.listdir(directory)
    file_list.sort()
    del file_list[0]
    
    for file in file_list:
        filename = directory + file
        all_text = '' 
        with pdfplumber.open(filename) as pdf:
            for pdf_page in pdf.pages:
                single_page_text = pdf_page.extract_text()
                all_text = all_text + '\n' + single_page_text
                committee[n]=all_text
        n=n+1   
                                
    with open(nv_json_name, 'w') as f: 
        json.dump(committee, f, ensure_ascii=False)

    
def nv_preprocess(nv_json_path):
    """
    Loads JSON into environment as dictionary
    Lightly preprocesses the raw PDF export from nv_pdftotext generated json

    
    Parameters
    ----------
    nv_json_path : STRING
        Local path of nv_json generated by nv_pdftotext.    
        
    Returns
    -------
    Lightly cleaned JSON file that removes PDF formatting and trailing white spaces

    """

    file_path = open(nv_json_path,)
    data = json.load(file_path)
    
    for key in data:
        data[key] = data[key].replace("\n", "")
        data[key] = data[key].strip()
        data[key]=" ".join(data[key].split())
    
    return(data)
    
def nv_procedural():
    """
    Removes procedural language to assist in text analysis
    
    Parameters
    ----------
    
    Returns
    -------
    Heavily cleaned JSON file that excludes committee procedural language

    """    
    
    

def nv_extract_date(nv_json_path):
    """
    
    Parameters
    ----------
    Local path of nv_json generated by nv_pdftotext.
        Local path of cleaned nv_json file. 
    Returns
    -------
    A new json file with month as the keys. We can call new_json_file[month] if we want the transcripts of meetings for this month.
    Eg: call new_json_file[4], we would get the transcripts for April.

    """
    data = open(nv_json_path)
    json_file = json.load(data)

    new_json_file = defaultdict(list)

    for key in json_file.keys():
        temp = json_file[key]
        match = re.search(r'(January|February|March|April|May|June|July|August|September|October|November|December)[ ]([1-9]|[12][0-9]|3[01])[,][ ]\d{4}', temp)
        date = datetime.datetime.strptime(match.group(), '%B %d, %Y').date()
        month = date.month
        new_json_file[month].append(temp)
        
     return new_json_file
   
